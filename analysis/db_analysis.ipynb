{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "from collections import namedtuple\n",
    "# %config InlineBackend.figure_format = 'retina'  # 提高 jupyter notebook 的圖形顯示解析度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/wmnlab/D/database'\n",
    "root = '/Users/jackbedford/Desktop/MOXA/Code/data'\n",
    "paths = [s for s in os.listdir(root) if s.startswith('202') and os.path.isdir(os.path.join(root, s))]\n",
    "\n",
    "md_files = []\n",
    "\n",
    "for date_dir in paths:\n",
    "    datedir = os.path.join(root, date_dir)\n",
    "    md_file = [os.path.join(datedir, s) for s in os.listdir(datedir) if s.endswith('.md')]\n",
    "    md_files += md_file\n",
    "\n",
    "md_files = sorted(md_files)\n",
    "\n",
    "# Select dates\n",
    "# md_files = md_files[:-1]\n",
    "# md_files = [md_files[2]]\n",
    "\n",
    "pprint(md_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, dir_name, setting):\n",
    "        \n",
    "        self.dir_name = dir_name\n",
    "        self.setting = setting\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.dir_name} -> {self.setting}'\n",
    "\n",
    "exp_list = []\n",
    "\n",
    "for md_file in md_files:\n",
    "    \n",
    "    md_f = open(md_file, 'r')\n",
    "    lines = []\n",
    "    l = md_f.readline()[:-1]\n",
    "    \n",
    "    while l:\n",
    "        \n",
    "        if l == '#endif':\n",
    "            break\n",
    "        lines.append(l)\n",
    "        l = md_f.readline()[:-1]\n",
    "        \n",
    "    md_f.close()\n",
    "    \n",
    "    for exp, dic in zip(lines[::2], lines[1::2]):\n",
    "        \n",
    "        dictionary = ast.literal_eval(dic)\n",
    "        parent_dir = os.path.dirname(md_file)\n",
    "        experiment = Experiment(dir_name = os.path.join(parent_dir, exp), setting=dictionary)\n",
    "        exp_list.append(experiment)\n",
    "        \n",
    "pprint(exp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set band parameters\n",
    "schms = ['All','LTE','B1','B3', 'B7', 'B8']\n",
    "\n",
    "rrc_dict = {}\n",
    "nr_dict = {}\n",
    "lte_dict = {}\n",
    "ul_pkt_dict = {}\n",
    "dl_pkt_dict = {}\n",
    "ul_sta_dict = {}\n",
    "dl_sta_dict = {}\n",
    "\n",
    "for schm in schms:\n",
    "        \n",
    "    path_list = []\n",
    "    \n",
    "    for exp in exp_list:\n",
    "        \n",
    "        reverse_dict = {v:k for k, v in exp.setting.items()}\n",
    "        \n",
    "        try:\n",
    "            dev = reverse_dict[schm]\n",
    "        except:\n",
    "            # print('warning:', schm)\n",
    "            continue\n",
    "        \n",
    "        device_dir = os.path.join(exp.dir_name, dev)\n",
    "        \n",
    "        for trace in os.listdir(device_dir):\n",
    "        \n",
    "            if '#' not in trace:\n",
    "                continue\n",
    "        \n",
    "            trace_dir = os.path.join(device_dir, trace, 'data')\n",
    "            path_list.append(trace_dir)\n",
    "\n",
    "    path_list = sorted(path_list)\n",
    "\n",
    "    rrc_list, nr_list, lte_list, ul_pkt_list, dl_pkt_list = [], [], [], [], []\n",
    "    ul_sta_list, dl_sta_list = [], []\n",
    "\n",
    "    for path in path_list:\n",
    "        \n",
    "        rrc_list += [os.path.join(path, s) for s in os.listdir(path) if s.endswith('_rrc.csv')]\n",
    "        nr_list += [os.path.join(path, s) for s in os.listdir(path) if s.endswith('_nr_ml1.csv')]\n",
    "        lte_list += [os.path.join(path, s) for s in os.listdir(path) if s.endswith('_ml1.csv') and not s.endswith('_nr_ml1.csv')]\n",
    "        ul_pkt_list += [os.path.join(path, 'udp_uplk_loss_latency.csv')]\n",
    "        dl_pkt_list += [os.path.join(path, 'udp_dnlk_loss_latency.csv')]\n",
    "        ul_sta_list += [os.path.join(path, 'udp_uplk_combo_statistics.csv')]\n",
    "        dl_sta_list += [os.path.join(path, 'udp_dnlk_combo_statistics.csv')]\n",
    "    \n",
    "    rrc_dict[schm] = rrc_list\n",
    "    nr_dict[schm] = nr_list\n",
    "    lte_dict[schm] = lte_list\n",
    "    ul_pkt_dict[schm] = ul_pkt_list\n",
    "    dl_pkt_dict[schm] = dl_pkt_list\n",
    "    ul_sta_dict[schm] = ul_sta_list\n",
    "    dl_sta_dict[schm] = dl_sta_list\n",
    "\n",
    "# rrc_dict['All'] = rrc_dict['All'] + rrc_dict['B3B7B8']\n",
    "# nr_dict['All'] = nr_dict['All'] + nr_dict['B3B7B8']\n",
    "# lte_dict['All'] = lte_dict['All'] + lte_dict['B3B7B8']\n",
    "# ul_pkt_dict['All'] = ul_pkt_dict['All'] + ul_pkt_dict['B3B7B8']\n",
    "# dl_pkt_dict['All'] = dl_pkt_dict['All'] + dl_pkt_dict['B3B7B8']\n",
    "\n",
    "# schms.remove('B3B7B8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/Users/jackbedford/Desktop/MOXA/Code/data/2023-04-17/Bandlock_Udp_All_LTE_All_LTE_RM500Q/combo'\n",
    "\n",
    "UL = []\n",
    "DL = []\n",
    "\n",
    "# for p1 in sorted([os.path.join(p, p_) for p_ in os.listdir(p)]):\n",
    "\n",
    "#     UL.append(os.path.join(p1, 'udp_uplk_combo_statistics.csv'))\n",
    "#     DL.append(os.path.join(p1, 'udp_dnlk_combo_statistics.csv'))\n",
    "\n",
    "p = '/home/wmnlab/D/database/2023-06-24/Modem_Action_Test/combo'\n",
    "\n",
    "for p1 in sorted([os.path.join(p, p_) for p_ in os.listdir(p)]):\n",
    "\n",
    "    UL.append(os.path.join(p1, 'udp_uplk_combo_statistics.csv'))\n",
    "    DL.append(os.path.join(p1, 'udp_dnlk_combo_statistics.csv'))\n",
    "\n",
    "    if '#06' in p1:\n",
    "        break\n",
    "\n",
    "DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss1 = []\n",
    "dl_exc_lat1 = []\n",
    "ul_loss1 = []\n",
    "ul_exc_lat1 = []\n",
    "\n",
    "for dl_target_file, ul_target_file in zip(DL, UL):\n",
    "    \n",
    "    if '04-17' in dl_target_file:\n",
    "        df = pd.read_csv(dl_target_file)\n",
    "        a = df['lost_All0+All2'].iloc[0]\n",
    "        b = df['excl_All0+All2'].iloc[0]\n",
    "        c = df['latency_All0+All2'].iloc[0]\n",
    "        dl_loss1.append(a), dl_exc_lat1.append(b)\n",
    "        print('dl',a,b,c)\n",
    "        \n",
    "        df = pd.read_csv(ul_target_file)\n",
    "        a = df['lost_All0+All2'].iloc[0]\n",
    "        b = df['excl_All0+All2'].iloc[0]\n",
    "        c = df['latency_All0+All2'].iloc[0]\n",
    "        ul_loss1.append(a), ul_exc_lat1.append(b)\n",
    "        print('ul',a,b,c)\n",
    "    elif '06-24' in dl_target_file:\n",
    "        df = pd.read_csv(dl_target_file)\n",
    "        a = df['lost_radio1+radio2'].iloc[0]\n",
    "        b = df['excl_radio1+radio2'].iloc[0]\n",
    "        c = df['latency_radio1+radio2'].iloc[0]\n",
    "        dl_loss1.append(a), dl_exc_lat1.append(b)\n",
    "        print(a,b,c)\n",
    "        \n",
    "        df = pd.read_csv(ul_target_file)\n",
    "        a = df['lost_radio1+radio2'].iloc[0]\n",
    "        b = df['excl_radio1+radio2'].iloc[0]\n",
    "        c = df['latency_radio1+radio2'].iloc[0]\n",
    "        ul_loss1.append(a), ul_exc_lat1.append(b)\n",
    "        print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss1, ul_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/wmnlab/D/database/2023-06-21/Modem_Action_Test/combo'\n",
    "\n",
    "UL = []\n",
    "DL = []\n",
    "\n",
    "# for p1 in sorted([os.path.join(p, p_) for p_ in os.listdir(p)]):\n",
    "\n",
    "#     UL.append(os.path.join(p1, 'udp_uplk_combo_statistics.csv'))\n",
    "#     DL.append(os.path.join(p1, 'udp_dnlk_combo_statistics.csv'))\n",
    "\n",
    "p = '/home/wmnlab/D/database/2023-06-24/Modem_Action_Test/combo'\n",
    "\n",
    "for p1 in sorted([os.path.join(p, p_) for p_ in os.listdir(p)]):\n",
    "\n",
    "    cont = False\n",
    "    for trace in [f'#0{x}' for x in range(1,7)]:\n",
    "        if trace in p1:\n",
    "            cont = True\n",
    "            break\n",
    "\n",
    "    if cont:\n",
    "        continue\n",
    "    \n",
    "    UL.append(os.path.join(p1, 'udp_uplk_combo_statistics.csv'))\n",
    "    DL.append(os.path.join(p1, 'udp_dnlk_combo_statistics.csv'))\n",
    "\n",
    "DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss2 = []\n",
    "dl_exc_lat2 = []\n",
    "ul_loss2 = []\n",
    "ul_exc_lat2 = []\n",
    "\n",
    "for dl_target_file, ul_target_file in zip(DL, UL):\n",
    "    \n",
    "    df = pd.read_csv(dl_target_file)\n",
    "    a = df['lost_radio1+radio2'].iloc[0]\n",
    "    b = df['excl_radio1+radio2'].iloc[0]\n",
    "    c = df['latency_radio1+radio2'].iloc[0]\n",
    "    dl_loss2.append(a), dl_exc_lat2.append(b)\n",
    "    print(a,b,c)\n",
    "    \n",
    "    df = pd.read_csv(ul_target_file)\n",
    "    a = df['lost_radio1+radio2'].iloc[0]\n",
    "    b = df['excl_radio1+radio2'].iloc[0]\n",
    "    c = df['latency_radio1+radio2'].iloc[0]\n",
    "    ul_loss2.append(a), ul_exc_lat2.append(b)\n",
    "    print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss2, ul_loss2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "name = ['Normal', 'With Change Band']\n",
    "\n",
    "plt.suptitle('DL Metrics')\n",
    "\n",
    "sns.boxplot(data=[dl_loss1, dl_loss2], width=0.3, ax=axes[0])\n",
    "axes[0].set_title('Loss Rate')\n",
    "axes[0].set_xticklabels(['Normal', 'with change band'])\n",
    "axes[0].set_ylabel('Percentage %')\n",
    "\n",
    "sns.boxplot(data=[dl_exc_lat1, dl_exc_lat2], width=0.3, ax=axes[1])\n",
    "axes[1].set_title('Excessive Latency Rate')\n",
    "axes[1].set_xticklabels(['Normal', 'with change band'])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "name = ['Normal', 'With Change Band']\n",
    "\n",
    "plt.suptitle('UL Metrics')\n",
    "\n",
    "sns.boxplot(data=[ul_loss1, ul_loss2], width=0.3, ax=axes[0])\n",
    "axes[0].set_title('Loss Rate')\n",
    "axes[0].set_xticklabels(['Normal', 'with change band'])\n",
    "axes[0].set_ylabel('Percentage %')\n",
    "\n",
    "sns.boxplot(data=[ul_exc_lat1, ul_exc_lat2], width=0.3, ax=axes[1])\n",
    "axes[1].set_title('Excessive Latency Rate')\n",
    "axes[1].set_xticklabels(['Normal', 'with change band'])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mi_ho(f):\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8))\n",
    "    nr_pci = ''\n",
    "\n",
    "    def NR_OTA():\n",
    "        if df[\"type_id\"].iloc[i] == \"5G_NR_RRC_OTA_Packet\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def find_1st_after(target, look_after=1):\n",
    "        for j in range(i, len(df)):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if (t_ - t).total_seconds() > look_after:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before(target, look_before=1):\n",
    "        for j in range(i, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    HO = namedtuple('HO','start, end, others', defaults=(None,None))\n",
    "\n",
    "    D = {\n",
    "        'Conn_Rel':[], \n",
    "        'Conn_Req':[], # Setup\n",
    "        'LTE_HO': [], # LTE -> newLTE\n",
    "        'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "        'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "        'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "        'SN_Rel': [], # LTE + NR -> LTE\n",
    "        'SN_HO': [], # LTE + NR -> LTE + newNR\n",
    "        'RLF_II': [],\n",
    "        'RLF_III': [],\n",
    "        'SCG_RLF': [],\n",
    "        }\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if NR_OTA():\n",
    "            continue\n",
    "\n",
    "        t = df[\"Timestamp\"].iloc[i]\n",
    "        \n",
    "        others = ''\n",
    "        if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "            D['Conn_Rel'].append(HO(start=t))\n",
    "\n",
    "        if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "            a = find_1st_after('rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "            b = find_1st_after('securityModeComplete',look_after=2)[0]\n",
    "            if a is None and b is None: end = None\n",
    "            elif a is None and b is not None: end = b\n",
    "            elif a is not None and b is None: end = a \n",
    "            else: end = a if a > b else b\n",
    "            \n",
    "            D['Conn_Req'].append(HO(start=t,end=end))\n",
    "            nr_pci = ''\n",
    "        \n",
    "        if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            end, _ = find_1st_after('rrcConnectionReconfigurationComplete')\n",
    "            serv_cell, target_cell = df[\"PCI\"].iloc[i], df['lte_targetPhysCellId'].iloc[i]\n",
    "            serv_freq, target_freq = df[\"Freq\"].iloc[i], df['dl-CarrierFreq'].iloc[i]\n",
    "\n",
    "            if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "                n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "                others=f'Set up {n} SCell.'\n",
    "            \n",
    "            if serv_freq != target_freq:\n",
    "                a,b = find_1st_before(\"rrcConnectionReestablishmentRequest\", 1)\n",
    "                others += \" Inter freq. HO.\"\n",
    "                if a is not None:\n",
    "                    others += \" Near after RLF.\"\n",
    "                \n",
    "            if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    D['SN_setup'].append(HO(start=t, end=end, others=others))\n",
    "                    nr_pci = df['nr_physCellId'].iloc[i]\n",
    "                else:    \n",
    "                    D['MN_HO'].append(HO(start=t, end=end, others=others))\n",
    "                    nr_pci = df['nr_physCellId'].iloc[i]\n",
    "            else:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    a, b = find_1st_before(\"scgFailureInformationNR-r15\")\n",
    "                    if a is not None:\n",
    "                        others += \" Caused by scg-failure.\"\n",
    "                    D['SN_Rel'].append(HO(start=t, end=end, others=others))\n",
    "                    nr_pci = ''\n",
    "                else:\n",
    "                    a, b = find_1st_before(\"rrcConnectionSetup\",3)\n",
    "                    if a is not None:\n",
    "                        others += 'Near After connection setup'\n",
    "                    if nr_pci == '':\n",
    "                        D['LTE_HO'].append(HO(start=t, end=end, others=others))\n",
    "                    else:\n",
    "                        D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others))\n",
    "\n",
    "        if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "            end, _ = find_1st_after('rrcConnectionReconfigurationComplete')\n",
    "            D['SN_HO'].append(HO(start=t,end=end))\n",
    "            nr_pci = df['nr_physCellId'].iloc[i]\n",
    "\n",
    "        if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "            end, _ = find_1st_after('rrcConnectionReestablishmentComplete', look_after=1)\n",
    "            b, _ = find_1st_after('rrcConnectionReestablishmentReject', look_after=1)\n",
    "            others = df[\"reestablishmentCause\"].iloc[i]\n",
    "            c, d = find_1st_before('scgFailureInformationNR-r15', 1)\n",
    "            if c != None:\n",
    "                others  += ' caused by scgfailure.'\n",
    "            if end is not None: \n",
    "                # Type II\n",
    "                D['RLF_II'].append(HO(start=t,end=end,others=others))\n",
    "            else: \n",
    "                # Type III\n",
    "                D['RLF_III'].append(HO(start=t,end=b,others=others)) # End for Type III?\n",
    "            \n",
    "        if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "            others = df[\"failureType-r15\"].iloc[i]\n",
    "            D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = '/home/wmnlab/D/database/2023-06-21/Modem_Action_Test/qc00'\n",
    "p2 = '/home/wmnlab/D/database/2023-06-21/Modem_Action_Test/qc03'\n",
    "p3 = '/home/wmnlab/D/database/2023-04-17/Bandlock_Udp_All_LTE_All_LTE_RM500Q/qc00'\n",
    "p4 = '/home/wmnlab/D/database/2023-04-17/Bandlock_Udp_All_LTE_All_LTE_RM500Q/qc02'\n",
    "\n",
    "rrc1 = []\n",
    "rrc2 = []\n",
    "rrc3 = []\n",
    "rrc4 = []\n",
    "\n",
    "for p11 in [os.path.join(p1, p_) for p_ in os.listdir(p1)]:\n",
    "\n",
    "    if 'combo' in p11:\n",
    "        continue\n",
    "\n",
    "    data_dir = os.path.join(p11, 'data')\n",
    "\n",
    "    rrc1 += [os.path.join(data_dir, s) for s in os.listdir(data_dir) if s.endswith('_rrc.csv')]\n",
    "\n",
    "for p11 in [os.path.join(p2, p_) for p_ in os.listdir(p2)]:\n",
    "\n",
    "    if 'combo' in p11:\n",
    "        continue\n",
    "\n",
    "    data_dir = os.path.join(p11, 'data')\n",
    "\n",
    "    rrc2 += [os.path.join(data_dir, s) for s in os.listdir(data_dir) if s.endswith('_rrc.csv')]\n",
    "\n",
    "for p11 in [os.path.join(p3, p_) for p_ in os.listdir(p3)]:\n",
    "\n",
    "    if 'combo' in p11:\n",
    "        continue\n",
    "\n",
    "    data_dir = os.path.join(p11, 'data')\n",
    "\n",
    "    rrc3 += [os.path.join(data_dir, s) for s in os.listdir(data_dir) if s.endswith('_rrc.csv')]\n",
    "\n",
    "for p11 in [os.path.join(p4, p_) for p_ in os.listdir(p4)]:\n",
    "\n",
    "    if 'combo' in p11:\n",
    "        continue\n",
    "\n",
    "    data_dir = os.path.join(p11, 'data')\n",
    "\n",
    "    rrc4 += [os.path.join(data_dir, s) for s in os.listdir(data_dir) if s.endswith('_rrc.csv')]\n",
    "\n",
    "rrc1.sort()\n",
    "rrc2.sort()\n",
    "rrc3.sort()\n",
    "rrc4.sort()\n",
    "\n",
    "pprint(rrc1)\n",
    "pprint(rrc2)\n",
    "pprint(rrc3)\n",
    "pprint(rrc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in rrc4:\n",
    "\n",
    "    evts = parse_mi_ho(f)\n",
    "\n",
    "    for k, v in evts.items():\n",
    "\n",
    "        print(f'{k}: {len(v)}')\n",
    "\n",
    "    print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in rrc1:\n",
    "\n",
    "    evts = parse_mi_ho(f)\n",
    "\n",
    "    for k, v in evts.items():\n",
    "\n",
    "        print(f'{k}: {len(v)}')\n",
    "\n",
    "    print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in rrc2:\n",
    "\n",
    "    evts = parse_mi_ho(f)\n",
    "\n",
    "    for k, v in evts.items():\n",
    "\n",
    "        print(f'{k}: {len(v)}')\n",
    "\n",
    "    print(evts)\n",
    "    print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
