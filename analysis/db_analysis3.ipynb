{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import re\n",
    "\n",
    "import itertools\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# This function input the path of experiment directory and output a list of device directories of the experiment directory.\n",
    "def find_device_under_exp(exp_dir_path):\n",
    "    dev_dir_list = sorted([os.path.join(exp_dir_path, d) for d in os.listdir(exp_dir_path) if d.startswith('qc') or d.startswith('sm')])\n",
    "    return dev_dir_list\n",
    "\n",
    "def find_trace_under_device(dev_dir_path):\n",
    "    trace_dir_list = sorted([os.path.join(dev_dir_path, d) for d in os.listdir(dev_dir_path)])\n",
    "    return trace_dir_list\n",
    "\n",
    "\n",
    "# Convenience instance\n",
    "class EXPERIMENT():\n",
    "    def __init__(self, exp_dir_path, settings):\n",
    "        self.path = exp_dir_path\n",
    "        self.settings = json.loads(settings)\n",
    "    def __repr__(self):\n",
    "        return f'EXP: {self.path} -> {self.settings}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mi_ho(f):\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8))\n",
    "    nr_pci = 'O'\n",
    "    scells = []\n",
    "\n",
    "    def NR_OTA():\n",
    "\n",
    "        if df[\"type_id\"].iloc[i] == \"5G_NR_RRC_OTA_Packet\": return True\n",
    "        else: return False\n",
    "    \n",
    "    def LTE_SERV_INFO():\n",
    "\n",
    "        if df[\"type_id\"].iloc[i] == \"LTE_RRC_Serv_Cell_Info\": return True\n",
    "        else: return False\n",
    "    \n",
    "\n",
    "    def find_1st_after(start_idx, target, look_after=1):\n",
    "        for j in range(start_idx, len(df)):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if (t_ - t).total_seconds() > look_after:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before(start_idx, target, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_in_D_exact(targets):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.start).total_seconds(), target))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            for x in l:\n",
    "                if (x[0]== 0):\n",
    "                    return x[1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def find_in_D_first_before(targets, look_before=1):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.end).total_seconds(), target))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            closest = min(l, key=lambda x: x[0])\n",
    "            if 0 <= closest[0] < look_before:\n",
    "                return closest[1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "    \n",
    "    D = {\n",
    "        'Conn_Rel':[], \n",
    "        'Conn_Req':[], # Setup\n",
    "        'LTE_HO': [], # LTE -> newLTE\n",
    "        'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "        'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "        'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "        'SN_Rel': [], # LTE + NR -> LTE\n",
    "        'SN_HO': [], # LTE + NR -> LTE + newNR  \n",
    "        'RLF_II': [],\n",
    "        'RLF_III': [],\n",
    "        'SCG_RLF': [],\n",
    "        'Add_SCell': [],\n",
    "        }\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # Pass NR RRC packet. In NSA mode, LTE RRC packet include NR packet message.\n",
    "        if NR_OTA() or LTE_SERV_INFO():\n",
    "            continue\n",
    "\n",
    "        others = ''\n",
    "        t = df[\"Timestamp\"].iloc[i]\n",
    "\n",
    "        if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "            D['Conn_Rel'].append(HO(start=t))\n",
    "            nr_pci = 'O'\n",
    "\n",
    "        if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "            # Define end of rrcConnectionRequest to be rrcConnectionReconfigurationComplete or securityModeComplete.\n",
    "            a = find_1st_after(i, 'rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "            b = find_1st_after(i, 'securityModeComplete',look_after=2)[0]\n",
    "            if a is None and b is None: end = None\n",
    "            elif a is None and b is not None: end = b\n",
    "            elif a is not None and b is None: end = a \n",
    "            else: end = a if a > b else b\n",
    "            \n",
    "            D['Conn_Req'].append(HO(start=t,end=end))\n",
    "            nr_pci = 'O'\n",
    "        \n",
    "        if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            \n",
    "            end, _ = find_1st_after(i, 'rrcConnectionReconfigurationComplete')\n",
    "            serv_cell, target_cell = df[\"PCI\"].iloc[i], int(df['lte_targetPhysCellId'].iloc[i])\n",
    "            serv_freq, target_freq = int(df[\"Freq\"].iloc[i]), int(df['dl-CarrierFreq'].iloc[i])\n",
    "\n",
    "\n",
    "            if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "                n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "                others += f' Set up {n} SCell.'\n",
    "            else:\n",
    "                scells = []\n",
    "            \n",
    "            if serv_freq != target_freq:\n",
    "                a,b = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 1)\n",
    "                others += \" Inter frequency HO.\"\n",
    "                if a is not None:\n",
    "                    others += \" Near after RLF.\"\n",
    "                \n",
    "            if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "                    if a is not None:\n",
    "                        others += ' Near after RLF.'\n",
    "\n",
    "                    a = find_in_D_first_before(['MN_HO_to_eNB', 'SN_Rel'])\n",
    "                    if a is not None:\n",
    "                        others += f' Near after {a}.'\n",
    "\n",
    "                    ori_serv = nr_pci\n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'{ori_serv} -> {nr_pci}'\n",
    "                    D['SN_setup'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    orig_serv = nr_pci\n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq})'\n",
    "                    D['MN_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, b = find_1st_before(i, \"scgFailureInformationNR-r15\", 2)\n",
    "                    if a is not None:\n",
    "                        others += \" Caused by scg-failure.\"\n",
    "                    \n",
    "                    orig_serv = nr_pci\n",
    "                    nr_pci = 'O'\n",
    "                    trans = f'{orig_serv} -> {nr_pci}'\n",
    "                    D['SN_Rel'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    a, _ = find_1st_before(i,\"rrcConnectionSetup\",3)\n",
    "                    if a is not None:\n",
    "                        others += ' Near After connection setup.'\n",
    "                    if nr_pci == 'O':\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq})'\n",
    "                        D['LTE_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    else:\n",
    "                        orig_serv = nr_pci\n",
    "                        nr_pci = 'O'\n",
    "                        trans = f'{orig_serv} -> {nr_pci}'\n",
    "                        D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "            orig_serv = nr_pci\n",
    "            nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "            trans = f'{orig_serv} -> {nr_pci}'\n",
    "            D['SN_HO'].append(HO(start=t,end=end,trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "\n",
    "            end1, _ = find_1st_after(i, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "            b, _ = find_1st_after(i, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "            end2, _ = find_1st_after(i, 'securityModeComplete',look_after=3)\n",
    "\n",
    "            others += ' ' + df[\"reestablishmentCause\"].iloc[i] + '.'\n",
    "            scells = []\n",
    "\n",
    "            c, _ = find_1st_before(i, 'scgFailureInformationNR-r15', 1)\n",
    "            if c != None:\n",
    "                others  += ' caused by scgfailure.'\n",
    "                \n",
    "            serv_cell, rlf_cell = df[\"PCI\"].iloc[i], int(df['physCellId.3'].iloc[i])\n",
    "            serv_freq = int(df['Freq'].iloc[i])\n",
    "            \n",
    "            # Type II & Type III\n",
    "            if end1 is not None: \n",
    "\n",
    "                orig_serv = nr_pci\n",
    "                nr_pci = 'O'\n",
    "                trans = f'({rlf_cell}) -> ({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_II'].append(HO(start=t,end=end1,others=others,trans=trans))\n",
    "\n",
    "            elif b is not None and end2 is not None: \n",
    "                D['RLF_III'].append(HO(start=t,end=end2,others=others))\n",
    "            else:\n",
    "                others+=' No end.'\n",
    "                D['RLF_II'].append(HO(start=t,others=others))\n",
    "                print('No end for RLF')\n",
    "\n",
    "        if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "\n",
    "            others += ' ' + df[\"failureType-r15\"].iloc[i] + '.'\n",
    "            a, idx1 = find_1st_after(i, \"rrcConnectionReestablishmentRequest\", look_after=1)\n",
    "            b, idx2 = find_1st_after(i, \"lte-rrc.t304\", look_after=2)\n",
    "\n",
    "            if a is not None:\n",
    "\n",
    "                end1, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "                b, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "                end2 = find_1st_after(idx1, 'securityModeComplete',look_after=3)[0]\n",
    "\n",
    "                others += ' Result in rrcReestablishment.'\n",
    "                    \n",
    "                # Type II & Type III Result\n",
    "                if end1 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end1,others=others))\n",
    "                elif b is not None and end2 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end2,others=others))\n",
    "                else:\n",
    "                    others += ' No end.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "                    print('No end for scg failure result in rrcReestablishment.')\n",
    "\n",
    "            elif b is not None:\n",
    "\n",
    "                end, _ = find_1st_after(idx2, 'rrcConnectionReconfigurationComplete')\n",
    "                serv_cell, target_cell = df[\"PCI\"].iloc[idx2], df['lte_targetPhysCellId'].iloc[idx2]\n",
    "                serv_freq, target_freq = df[\"Freq\"].iloc[idx2], df['dl-CarrierFreq'].iloc[idx2]\n",
    "                others += ' Result in gNB release.'\n",
    "\n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others))\n",
    "                else:\n",
    "                    others += ' Weird gNB release.'\n",
    "                    print('Weird for scg failure result in gNb Release.')\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others))                  \n",
    "\n",
    "            else:\n",
    "\n",
    "                print('No end for scg failure.')\n",
    "                others += ' No end.'\n",
    "                D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "        \n",
    "        if df['SCellToAddMod-r10'].iloc[i] == 1 and df['physCellId-r10'].iloc[i] != 'nr or cqi report':\n",
    "\n",
    "            others = ''\n",
    "            pcis = str(df[\"physCellId-r10\"].iloc[i]).split('@')\n",
    "            freqs = str(df[\"dl-CarrierFreq-r10\"].iloc[i]).split('@')\n",
    "            orig_scells = scells\n",
    "            scells = [(int(float(pci)), int(float(freq))) for pci, freq in zip(pcis, freqs)]\n",
    "\n",
    "            others += f' Set up {len(scells)} SCell.'\n",
    "            trans = f'{orig_scells} -> {scells}'\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "            a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "            if a is not None:\n",
    "                others += ' Near after RLF.'\n",
    "\n",
    "            a = find_in_D_exact(['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel'])\n",
    "            if a is not None:\n",
    "                others += f' With {a}.'\n",
    "\n",
    "            D['Add_SCell'].append(HO(start=t,end=end,others=others, trans=trans))\n",
    "    \n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_excl_cause(loss_lat_file_path, rrc_file_path):\n",
    "\n",
    "    loss_lat_df = pd.read_csv(loss_lat_file_path)\n",
    "\n",
    "    loss_cond = loss_lat_df['lost'] == True\n",
    "    loss_packets = loss_lat_df[loss_cond]\n",
    "    loss_packets = loss_packets.reset_index(drop=True)\n",
    "    loss_packets['Timestamp'] = pd.to_datetime(loss_packets['Timestamp'])\n",
    "\n",
    "    exc_lat = 0.1\n",
    "    excl_cond = (loss_cond==False) & (loss_lat_df['latency'] > exc_lat)\n",
    "    excl_packets = loss_lat_df[excl_cond]\n",
    "    excl_packets = excl_packets.reset_index(drop=True)\n",
    "    excl_packets['Timestamp'] = pd.to_datetime(excl_packets['Timestamp'])\n",
    "\n",
    "    HO_dict = parse_mi_ho(rrc_file_path)\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2)]\n",
    "    \n",
    "    LOSS_PKT = namedtuple('LOSS_PKT',['timestamp', 'seq', 'cause', 'trans', 'trans_time'], defaults=['', 0, [], [], []])\n",
    "\n",
    "    LOSS_PKTs = []\n",
    "\n",
    "    for i in range(len(loss_packets)):\n",
    "\n",
    "        loss_packet = loss_packets.iloc[i]\n",
    "        loss_packet_timestamp = loss_packet['Timestamp']\n",
    "        seq = loss_packet['seq']\n",
    "        \n",
    "        cause = []\n",
    "        trans = []\n",
    "        trans_time = []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs = HO_dict[HO_type]  \n",
    "\n",
    "            for h in HOs:\n",
    "                \n",
    "                if h.start - slot < loss_packet_timestamp < h.start:\n",
    "                    cause.append(f'Before {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.start)\n",
    "                elif h.start < loss_packet_timestamp < h.end:\n",
    "                    cause.append(f'During {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append((h.start, h.end))\n",
    "                elif h.end < loss_packet_timestamp < h.end + slot:\n",
    "                    cause.append(f'After {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.end)\n",
    "\n",
    "        LOSS_PKTs.append(LOSS_PKT(timestamp=loss_packet_timestamp, seq=seq, cause=cause))\n",
    "                \n",
    "    EXCL_PKT = namedtuple('EXCL_PKT',['timestamp', 'seq', 'cause', 'trans', 'trans_time'], defaults=['', 0, [], [], []])\n",
    "\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=1)]\n",
    "    \n",
    "    EXCL_PKTs = []\n",
    "\n",
    "    for i in range(len(excl_packets)):\n",
    "\n",
    "        excl_packet = excl_packets.iloc[i]\n",
    "        excl_packet_timestamp = excl_packet['Timestamp']\n",
    "        seq = excl_packet['seq']\n",
    "\n",
    "        cause = []\n",
    "        trans = []\n",
    "        trans_time = []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs = HO_dict[HO_type]   \n",
    "            for h in HOs:\n",
    "                \n",
    "                if h.start - slot < excl_packet_timestamp < h.start:\n",
    "                    cause.append(f'Before {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.start)\n",
    "                elif h.start < excl_packet_timestamp < h.end:\n",
    "                    cause.append(f'During {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append((h.start, h.end))\n",
    "                elif h.end < excl_packet_timestamp < h.end + slot:\n",
    "                    cause.append(f'After {HO_type}') \n",
    "                    trans.append(h.trans)\n",
    "                    trans_time.append(h.end)\n",
    "\n",
    "        EXCL_PKTs.append(EXCL_PKT(timestamp=excl_packet_timestamp, seq=seq, cause=cause, trans=trans, trans_time=trans_time))\n",
    "    \n",
    "    return LOSS_PKTs, EXCL_PKTs\n",
    "\n",
    "\n",
    "def loss_excl_cause_dual(loss_lat_file_path1, loss_lat_file_path2, rrc_file_path1, rrc_file_path2):\n",
    "\n",
    "    df1 = pd.read_csv(loss_lat_file_path1)\n",
    "    df2 = pd.read_csv(loss_lat_file_path2)\n",
    "\n",
    "    start_seq = df1['seq'].iloc[0] if df1['seq'].iloc[0] >=  df2['seq'].iloc[0] else df2['seq'].iloc[0]\n",
    "    end_seq = df1['seq'].iloc[-1] if df1['seq'].iloc[-1] <=  df2['seq'].iloc[-1] else df2['seq'].iloc[-1]\n",
    "\n",
    "    cond1 = (df1['seq'] >= start_seq) & (df1['seq'] <= end_seq)\n",
    "    df1 = df1[cond1]\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    cond2 = (df2['seq'] >= start_seq) & (df2['seq'] <= end_seq)\n",
    "    df2 = df2[cond2]\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # Loss calculate for dual radios redundant packets.\n",
    "    loss_cond = (df1['lost'] == True) & (df2['lost'] == True)\n",
    "\n",
    "    loss_packets1 = df1[loss_cond]\n",
    "    loss_packets1 = loss_packets1.reset_index(drop=True)\n",
    "    loss_packets1['Timestamp'] = pd.to_datetime(loss_packets1['Timestamp'])\n",
    "\n",
    "    loss_packets2 = df2[loss_cond]\n",
    "    loss_packets2 = loss_packets2.reset_index(drop=True)\n",
    "    loss_packets2['Timestamp'] = pd.to_datetime(loss_packets2['Timestamp'])\n",
    "\n",
    "    # Excexxive latency calculate for dual radios redundant packets.\n",
    "    exc_lat = 0.1 \n",
    "    excl_cond1 = (loss_cond==False) & (df1['latency'] > exc_lat)\n",
    "    excl_cond2 = (loss_cond==False) & (df2['latency'] > exc_lat)\n",
    "    excl_cond = (excl_cond1 == True) & (excl_cond2 == True)\n",
    "    \n",
    "    excl_packets1 = df1[excl_cond]\n",
    "    excl_packets1 = excl_packets1.reset_index(drop=True)\n",
    "    excl_packets1['Timestamp'] = pd.to_datetime(excl_packets1['Timestamp'])\n",
    "\n",
    "    excl_packets2 = df2[excl_cond]\n",
    "    excl_packets2 = excl_packets2.reset_index(drop=True)\n",
    "    excl_packets2['Timestamp'] = pd.to_datetime(excl_packets2['Timestamp'])\n",
    "\n",
    "    HO_dict1 = parse_mi_ho(rrc_file_path1)\n",
    "    HO_dict2 = parse_mi_ho(rrc_file_path2)\n",
    "    \n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2)]\n",
    "    \n",
    "    LOSS_PKT_DUAL = namedtuple('LOSS_PKT_DUAL',\n",
    "                               ['timestamp1', 'timestamp2', 'seq', 'cause1', 'cause2', 'trans1', 'trans2', 'trans1_time', 'trans2_time'], \n",
    "                               defaults=['', '', 0, [], [], [], [], [], []])\n",
    "\n",
    "    LOSS_PKT_DUALs = []\n",
    "\n",
    "    for i in range(len(loss_packets1)):\n",
    "\n",
    "        loss_packet1 = loss_packets1.iloc[i]\n",
    "        loss_packet1_timestamp = loss_packet1['Timestamp']\n",
    "\n",
    "        loss_packet2 = loss_packets2.iloc[i]\n",
    "        loss_packet2_timestamp = loss_packet2['Timestamp']\n",
    "\n",
    "        seq = loss_packet1['seq']\n",
    "        \n",
    "        cause1, cause2 = [], []\n",
    "        trans1, trans2 = [], []\n",
    "        trans1_time, trans2_time = [], []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs1 = HO_dict1[HO_type]\n",
    "            HOs2 = HO_dict2[HO_type]   \n",
    "\n",
    "            for h in HOs1:\n",
    "                \n",
    "                if h.start - slot < loss_packet1_timestamp < h.start:\n",
    "                    cause1.append(f'Before {HO_type}') \n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.start)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < loss_packet1_timestamp < h.end):\n",
    "                    cause1.append(f'During {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append((h.start, h.end))\n",
    "\n",
    "                elif (h.end is not None) and (h.end < loss_packet1_timestamp < h.end + slot):\n",
    "                    cause1.append(f'After {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.end)\n",
    "            \n",
    "            for h in HOs2:\n",
    "                \n",
    "                if h.start - slot < loss_packet2_timestamp < h.start:\n",
    "                    cause2.append(f'Before {HO_type}') \n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.start)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < loss_packet2_timestamp < h.end):\n",
    "                    cause2.append(f'During {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append((h.start, h.end))\n",
    "\n",
    "                elif (h.end is not None) and (h.end < loss_packet2_timestamp < h.end + slot):\n",
    "                    cause2.append(f'After {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.end)\n",
    "    \n",
    "        LOSS_PKT_DUALs.append(LOSS_PKT_DUAL(timestamp1=loss_packet1_timestamp, timestamp2=loss_packet2_timestamp, seq=seq, \n",
    "        cause1=cause1, cause2=cause2, trans1=trans1, trans2=trans2, trans1_time=trans1_time, trans2_time=trans2_time))\n",
    "                \n",
    "    slot = dt.timedelta(seconds=2)\n",
    "    EXCL_PKT_DUAL = namedtuple('EXCL_PKT_DUAL',\n",
    "                               ['timestamp1', 'timestamp2', 'seq', 'cause1', 'cause2', 'trans1', 'trans2', 'trans1_time', 'trans2_time'], \n",
    "                               defaults=['', '', 0, [], [], [], [], [], []])\n",
    "\n",
    "    events = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "              'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "    slots = [dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=1),\n",
    "             dt.timedelta(seconds=1), dt.timedelta(seconds=1), dt.timedelta(seconds=2), dt.timedelta(seconds=2), dt.timedelta(seconds=2)]\n",
    "    \n",
    "    \n",
    "    EXCL_PKT_DUALs = []\n",
    "\n",
    "    for i in range(len(excl_packets1)):\n",
    "\n",
    "        excl_packet1 = excl_packets1.iloc[i]\n",
    "        excl_packet1_timestamp = excl_packet1['Timestamp']\n",
    "        excl_packet2 = excl_packets2.iloc[i]\n",
    "        excl_packet2_timestamp = excl_packet2['Timestamp']\n",
    "\n",
    "        seq = excl_packet1['seq']\n",
    "\n",
    "        cause1, cause2 = [], []\n",
    "        trans1, trans2 = [], []\n",
    "        trans1_time, trans2_time = [], []\n",
    "\n",
    "        for HO_type, slot in zip(events, slots):\n",
    "            \n",
    "            HOs1 = HO_dict1[HO_type]\n",
    "            HOs2 = HO_dict2[HO_type]\n",
    "\n",
    "            for h in HOs1:\n",
    "                \n",
    "                if h.start - slot < excl_packet1_timestamp < h.start:\n",
    "                    cause1.append(f'Before {HO_type}') \n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.start)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < excl_packet1_timestamp < h.end):\n",
    "                    cause1.append(f'During {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append((h.start, h.end))\n",
    "\n",
    "                elif (h.end is not None) and (h.end < excl_packet1_timestamp < h.end + slot):\n",
    "                    cause1.append(f'After {HO_type}')\n",
    "                    trans1.append(h.trans)\n",
    "                    trans1_time.append(h.end)\n",
    "\n",
    "            for h in HOs2:\n",
    "                \n",
    "                if h.start - slot < excl_packet2_timestamp < h.start:\n",
    "                    cause2.append(f'Before {HO_type}') \n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append(h.start)\n",
    "\n",
    "                elif (h.end is not None) and (h.start < excl_packet2_timestamp < h.end):\n",
    "                    cause2.append(f'During {HO_type}')\n",
    "                    trans2.append(h.trans)\n",
    "                    trans2_time.append((h.start, h.end))\n",
    "\n",
    "                elif (h.end is not None) and (h.end < excl_packet2_timestamp < h.end + slot):\n",
    "                    cause2.append(f'After {HO_type}')\n",
    "                    trans2.append(h.trans)                   \n",
    "                    trans2_time.append(h.end)\n",
    "\n",
    "        EXCL_PKT_DUALs.append(EXCL_PKT_DUAL(timestamp1=excl_packet1_timestamp, timestamp2=excl_packet2_timestamp, seq=seq, \n",
    "        cause1=cause1, cause2=cause2, trans1=trans1, trans2=trans2, trans1_time=trans1_time, trans2_time=trans2_time))\n",
    "\n",
    "    return LOSS_PKT_DUALs, EXCL_PKT_DUALs\n",
    "\n",
    "# Analyse every case.\n",
    "EVENTS = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', \n",
    "        'SN_Rel', 'SN_HO', 'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "EVENTS1 = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB']\n",
    "CASES = ['all', 'two_RLF', 'two_scg_failure', 'one_RLF_one_scg', 'one_RLF', 'one_scg_failure'] + \\\n",
    "        ['two_identicle_HO'] + [f'two_identicle_{type}' for type in EVENTS] + \\\n",
    "        ['two_identicle_RLF_SN_setup'] + \\\n",
    "        ['pci_identicle_HO'] + [f'pci_identicle_{type}' for type in EVENTS1]\n",
    "\n",
    "ANALYSIS = namedtuple('ANALYSIS', CASES, defaults = [0]*len(CASES))\n",
    "\n",
    "def Analyze(pkgs):\n",
    "    \n",
    "    # case functions.\n",
    "    # Case source and target cause type, trans are exactly the same.\n",
    "    # A is cause list and B is trans list.\n",
    "    def find_identicle(A1, B1, A2, B2):\n",
    "\n",
    "        L = []\n",
    "        # Take out before, during, and after.\n",
    "        A1 = [a1.split(' ')[-1] for a1 in A1]\n",
    "        A2 = [a2.split(' ')[-1] for a2 in A2]\n",
    "\n",
    "        for i, (a1, b1) in enumerate(zip(A1, B1)):    \n",
    "            for j, (a2, b2) in enumerate(zip(A2, B2)):\n",
    "                if a1 == a2 and b1 == b2:\n",
    "                    L.append((i, j))\n",
    "        return L\n",
    "    \n",
    "    # Case source and target cause type, trans pci are exactly the same.\n",
    "    # A is cause list and B is trans list.\n",
    "    # This case only deal with ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB'].\n",
    "    def find_pci_identicle(A1, B1, A2, B2):\n",
    "\n",
    "        L = []\n",
    "\n",
    "        def extract_coordinates(input_string):\n",
    "            pattern = r'\\((\\d+), (\\d+)\\) -> \\((\\d+), (\\d+)\\)'\n",
    "            match = re.match(pattern, input_string)\n",
    "            \n",
    "            if match:\n",
    "                return f'{match.group(1)} -> {match.group(3)}'\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # Take out before, during, and after.\n",
    "        A1 = [a1.split(' ')[-1] for a1 in A1]\n",
    "        A2 = [a2.split(' ')[-1] for a2 in A2]\n",
    "        B1 = [extract_coordinates(b1) for b1 in B1]\n",
    "        B2 = [extract_coordinates(b2) for b2 in B2]\n",
    "\n",
    "        for i, (a1, b1) in enumerate(zip(A1, B1)):    \n",
    "            for j, (a2, b2) in enumerate(zip(A2, B2)):\n",
    "                \n",
    "                if a1 not in EVENTS1 or a2 not in EVENTS1:\n",
    "                    continue\n",
    "\n",
    "                if a1 == a2 and b1 == b2:\n",
    "                    L.append((i, j))\n",
    "        return L\n",
    "\n",
    "    # Count the number of every case. \n",
    "    nums = {k: 0 for k in CASES}\n",
    "    nums['all'] = len(pkgs)\n",
    "\n",
    "    for pkg in pkgs:\n",
    "\n",
    "        cause1_string = \"\".join(pkg.cause1)\n",
    "        cause2_string = \"\".join(pkg.cause2)\n",
    "\n",
    "        if ('RLF_' in cause1_string) and ('RLF_' in cause2_string):   \n",
    "            nums['two_RLF'] += 1\n",
    "\n",
    "        elif ('SCG_RLF' in cause1_string) and ('SCG_RLF' in cause2_string): \n",
    "            nums['two_scg_failure'] += 1\n",
    "        \n",
    "        elif (('RLF_' in cause1_string) and ('SCG_RLF' in cause2_string) ) or (('SCG_RLF' in cause1_string) and ('RLF_' in cause2_string) ):\n",
    "            nums['one_RLF_one_scg'] += 1\n",
    "\n",
    "        elif ('SCG_RLF' in cause1_string) or ('SCG_RLF' in cause2_string): \n",
    "            nums['one_scg_failure'] += 1\n",
    "\n",
    "        elif ('RLF_' in cause1_string) or ('RLF_' in cause2_string):  \n",
    "            nums['one_RLF'] += 1\n",
    "\n",
    "        L1 = find_identicle(pkg.cause1, pkg.trans1, pkg.cause2, pkg.trans2)\n",
    "        if len(L1) != 0: nums['two_identicle_HO'] += 1\n",
    "        \n",
    "        identicle_types = []\n",
    "        for (i, _) in L1:\n",
    "            _, ho_type = pkg.cause1[i].split(' ')\n",
    "            identicle_types.append(ho_type)\n",
    "            nums[f'two_identicle_{ho_type}'] += 1\n",
    "\n",
    "        if ('RLF_II' in identicle_types or 'RLF_III' in identicle_types) and ('SN_setup' in identicle_types):\n",
    "            nums[f'two_identicle_RLF_SN_setup'] += 1\n",
    "\n",
    "\n",
    "        L2 = find_pci_identicle(pkg.cause1, pkg.trans1, pkg.cause2, pkg.trans2)\n",
    "        L2 = [element for element in L2 if element not in L1] # Take out repeated element in L1. \n",
    "\n",
    "        if len(L2) != 0: nums['pci_identicle_HO'] += 1\n",
    "\n",
    "        for (i, _) in L2:\n",
    "            _, ho_type = pkg.cause1[i].split(' ')\n",
    "            nums[f'pci_identicle_{ho_type}'] += 1        \n",
    "\n",
    "    return ANALYSIS(*nums.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrc_file_path1 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_rrc.csv'\n",
    "ml1_file_path1 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_ml1.csv'\n",
    "nr_ml1_file_path1 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_nr_ml1.csv'\n",
    "dl_file_path1 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/udp_dnlk_loss_latency.csv'\n",
    "ul_file_path1 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/udp_uplk_loss_latency.csv'\n",
    "\n",
    "rrc_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm03/#01/data/diag_log_sm03_2023-06-12_16-30-21_rrc.csv'\n",
    "ml1_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm03/#01/data/diag_log_sm03_2023-06-12_16-30-21_ml1.csv'\n",
    "nr_ml1_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm03/#01/data/diag_log_sm03_2023-06-12_16-30-21_nr_ml1.csv'\n",
    "dl_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm03/#01/data/udp_dnlk_loss_latency.csv'\n",
    "ul_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm03/#01/data/udp_uplk_loss_latency.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrc_file_path1 = \"/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#01/data/diag_log_sm00_2023-06-12_16-30-21_rrc.csv\"\n",
    "ml1_file_path1 = \"/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#01/data/diag_log_sm00_2023-06-12_16-30-21_ml1.csv\"\n",
    "nr_ml1_file_path1 = \"/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#01/data/diag_log_sm00_2023-06-12_16-30-21_nr_ml1.csv\"\n",
    "dl_file_path1 = \"/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#01/data/udp_dnlk_loss_latency.csv\"\n",
    "ul_file_path1 = \"/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#01/data/udp_uplk_loss_latency.csv\"\n",
    "\n",
    "rrc_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_rrc.csv'\n",
    "ml1_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_ml1.csv'\n",
    "nr_ml1_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/diag_log_sm01_2023-06-12_16-30-21_nr_ml1.csv'\n",
    "dl_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/udp_dnlk_loss_latency.csv'\n",
    "ul_file_path2 = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#01/data/udp_uplk_loss_latency.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = loss_excl_cause_dual(ul_file_path1, ul_file_path2, rrc_file_path1, rrc_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXCL_PKT_DUAL(timestamp1=Timestamp('2023-06-12 16:33:12.853898256'), timestamp2=Timestamp('2023-06-12 16:33:12.852297528'), seq=93517, cause1=['Before MN_HO', 'After SN_HO'], cause2=['Before MN_HO'], trans1=['(73, 1750) -> (294, 1750)', '16 -> 73'], trans2=['(73, 1750) -> (294, 1750)'], trans1_time=[Timestamp('2023-06-12 16:33:13.243937'), Timestamp('2023-06-12 16:33:12.340381')], trans2_time=[Timestamp('2023-06-12 16:33:13.824280')])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg = b[20]\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EXP: /home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone -> {'sm00': 'B3B7B8', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This place give a XXXX-XX-XX.md file and find the experiment directory path\n",
    "# and the corresponding band settings. It will be presented by a list of special\n",
    "# instance EXPERIMENTs.\n",
    "\n",
    "md_file_path = '/home/wmnlab/D/database/2023-06-12/2023-06-12.md'\n",
    "date_dir_path = os.path.dirname(md_file_path)\n",
    "EXPs = []\n",
    "\n",
    "with open(md_file_path) as f:\n",
    "\n",
    "    exp = f.readline()[:-1]\n",
    "    settings = f.readline()[:-1]\n",
    "\n",
    "    while exp != '#endif' and settings:\n",
    "        E = EXPERIMENT(os.path.join(date_dir_path, exp), settings)\n",
    "        EXPs.append(E)\n",
    "        exp = f.readline()[:-1]\n",
    "        settings = f.readline()[:-1]\n",
    "\n",
    "EXPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm00 sm01\n",
      "sm00 sm02\n",
      "sm00 sm03\n",
      "sm00 sm04\n",
      "sm00 sm05\n",
      "sm00 sm06\n",
      "sm00 sm07\n",
      "sm01 sm02\n",
      "sm01 sm03\n",
      "sm01 sm04\n",
      "sm01 sm05\n",
      "sm01 sm06\n",
      "sm01 sm07\n",
      "sm02 sm03\n",
      "sm02 sm04\n",
      "sm02 sm05\n",
      "sm02 sm06\n",
      "sm02 sm07\n",
      "sm03 sm04\n",
      "sm03 sm05\n",
      "sm03 sm06\n",
      "sm03 sm07\n",
      "sm04 sm05\n",
      "sm04 sm06\n",
      "sm04 sm07\n",
      "sm05 sm06\n",
      "sm05 sm07\n",
      "sm06 sm07\n"
     ]
    }
   ],
   "source": [
    "# \"This code counts the number of occurrences for each case\n",
    "#  \n",
    "\n",
    "# Still need to revise here.\n",
    "EXP = EXPs[0]\n",
    "exp_dir_path = EXP.path\n",
    "settings = EXP.settings \n",
    "\n",
    "dev_dir_list = find_device_under_exp(exp_dir_path)\n",
    "comb = itertools.combinations(dev_dir_list, 2)\n",
    "\n",
    "# Record\n",
    "keys = ['dl_loss', 'dl_excl', 'ul_loss', 'ul_excl']\n",
    "cases = ANALYSIS._fields\n",
    "analysis_dict_all = {}\n",
    "for k in keys:\n",
    "    analysis_dict_all[k] = {case: 0 for case in cases}\n",
    "\n",
    "analysis_dicts = []\n",
    "corresponding_list = []\n",
    "\n",
    "for dev_dir_path1, dev_dir_path2 in comb:\n",
    "    \n",
    "    dev1 = dev_dir_path1.split('/')[-1]\n",
    "    dev2 = dev_dir_path2.split('/')[-1]\n",
    "    print(dev1, dev2)\n",
    "\n",
    "    trace_dir_list1 = find_trace_under_device(dev_dir_path1)\n",
    "    trace_dir_list2 = find_trace_under_device(dev_dir_path2)\n",
    "\n",
    "    for trace_dir_path1, trace_dir_path2 in zip(trace_dir_list1, trace_dir_list2):\n",
    "\n",
    "        trace = trace_dir_path1.split('/')[-1]\n",
    "\n",
    "        data_dir_path1 = os.path.join(trace_dir_path1, 'data')\n",
    "        rrc_file1 = [p for p in os.listdir(data_dir_path1) if p.endswith('_rrc.csv')][0]\n",
    "        rrc_file_path1 = os.path.join(data_dir_path1, rrc_file1)\n",
    "        dl_file_path1 = os.path.join(data_dir_path1, 'udp_dnlk_loss_latency.csv')\n",
    "        ul_file_path1 = os.path.join(data_dir_path1, 'udp_uplk_loss_latency.csv')\n",
    "\n",
    "        data_dir_path2 = os.path.join(trace_dir_path2, 'data')\n",
    "        rrc_file2 = [p for p in os.listdir(data_dir_path2) if p.endswith('_rrc.csv')][0]\n",
    "        rrc_file_path2 = os.path.join(data_dir_path2, rrc_file2)\n",
    "        dl_file_path2 = os.path.join(data_dir_path2, 'udp_dnlk_loss_latency.csv')\n",
    "        ul_file_path2 = os.path.join(data_dir_path2, 'udp_uplk_loss_latency.csv')\n",
    "    \n",
    "        dl_loss_pkgs, dl_excl_pkgs  = loss_excl_cause_dual(dl_file_path1, dl_file_path2, rrc_file_path1, rrc_file_path2)\n",
    "        ul_loss_pkgs, ul_excl_pkgs = loss_excl_cause_dual(ul_file_path1, ul_file_path2, rrc_file_path1, rrc_file_path2)\n",
    "\n",
    "        keys = ['dl_loss', 'dl_excl', 'ul_loss', 'ul_excl']\n",
    "        values = [Analyze(dl_loss_pkgs), Analyze(dl_excl_pkgs), Analyze(ul_loss_pkgs), Analyze(ul_excl_pkgs)]\n",
    "        analysis_dict = {k: v for k, v in zip(keys, values)}\n",
    "        \n",
    "        for k in keys:\n",
    "            for i, case in enumerate(cases):\n",
    "                analysis_dict_all[k][case] += analysis_dict[k][i]\n",
    "        \n",
    "        analysis_dicts.append(analysis_dict)\n",
    "        corresponding_list.append((dev1, dev2, trace))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dl_loss': {'all': 63886,\n",
       "  'two_RLF': 34816,\n",
       "  'two_scg_failure': 0,\n",
       "  'one_RLF_one_scg': 549,\n",
       "  'one_RLF': 21440,\n",
       "  'one_scg_failure': 851,\n",
       "  'two_identicle_HO': 25970,\n",
       "  'two_identicle_LTE_HO': 652,\n",
       "  'two_identicle_MN_HO': 605,\n",
       "  'two_identicle_MN_HO_to_eNB': 0,\n",
       "  'two_identicle_SN_setup': 19037,\n",
       "  'two_identicle_SN_Rel': 0,\n",
       "  'two_identicle_SN_HO': 827,\n",
       "  'two_identicle_RLF_II': 10696,\n",
       "  'two_identicle_RLF_III': 0,\n",
       "  'two_identicle_SCG_RLF': 0,\n",
       "  'two_identicle_RLF_SN_setup': 5175,\n",
       "  'pci_identicle_HO': 1011,\n",
       "  'pci_identicle_LTE_HO': 905,\n",
       "  'pci_identicle_MN_HO': 59,\n",
       "  'pci_identicle_MN_HO_to_eNB': 47},\n",
       " 'dl_excl': {'all': 44934,\n",
       "  'two_RLF': 3406,\n",
       "  'two_scg_failure': 97,\n",
       "  'one_RLF_one_scg': 434,\n",
       "  'one_RLF': 9651,\n",
       "  'one_scg_failure': 1076,\n",
       "  'two_identicle_HO': 8137,\n",
       "  'two_identicle_LTE_HO': 0,\n",
       "  'two_identicle_MN_HO': 342,\n",
       "  'two_identicle_MN_HO_to_eNB': 27,\n",
       "  'two_identicle_SN_setup': 1874,\n",
       "  'two_identicle_SN_Rel': 0,\n",
       "  'two_identicle_SN_HO': 5819,\n",
       "  'two_identicle_RLF_II': 546,\n",
       "  'two_identicle_RLF_III': 0,\n",
       "  'two_identicle_SCG_RLF': 97,\n",
       "  'two_identicle_RLF_SN_setup': 257,\n",
       "  'pci_identicle_HO': 205,\n",
       "  'pci_identicle_LTE_HO': 11,\n",
       "  'pci_identicle_MN_HO': 45,\n",
       "  'pci_identicle_MN_HO_to_eNB': 149},\n",
       " 'ul_loss': {'all': 3710,\n",
       "  'two_RLF': 1088,\n",
       "  'two_scg_failure': 0,\n",
       "  'one_RLF_one_scg': 0,\n",
       "  'one_RLF': 213,\n",
       "  'one_scg_failure': 8,\n",
       "  'two_identicle_HO': 650,\n",
       "  'two_identicle_LTE_HO': 0,\n",
       "  'two_identicle_MN_HO': 1,\n",
       "  'two_identicle_MN_HO_to_eNB': 0,\n",
       "  'two_identicle_SN_setup': 600,\n",
       "  'two_identicle_SN_Rel': 0,\n",
       "  'two_identicle_SN_HO': 7,\n",
       "  'two_identicle_RLF_II': 156,\n",
       "  'two_identicle_RLF_III': 0,\n",
       "  'two_identicle_SCG_RLF': 0,\n",
       "  'two_identicle_RLF_SN_setup': 114,\n",
       "  'pci_identicle_HO': 0,\n",
       "  'pci_identicle_LTE_HO': 0,\n",
       "  'pci_identicle_MN_HO': 0,\n",
       "  'pci_identicle_MN_HO_to_eNB': 0},\n",
       " 'ul_excl': {'all': 1031406,\n",
       "  'two_RLF': 19821,\n",
       "  'two_scg_failure': 1155,\n",
       "  'one_RLF_one_scg': 661,\n",
       "  'one_RLF': 20983,\n",
       "  'one_scg_failure': 28889,\n",
       "  'two_identicle_HO': 57940,\n",
       "  'two_identicle_LTE_HO': 257,\n",
       "  'two_identicle_MN_HO': 23483,\n",
       "  'two_identicle_MN_HO_to_eNB': 20,\n",
       "  'two_identicle_SN_setup': 13424,\n",
       "  'two_identicle_SN_Rel': 342,\n",
       "  'two_identicle_SN_HO': 17817,\n",
       "  'two_identicle_RLF_II': 6672,\n",
       "  'two_identicle_RLF_III': 0,\n",
       "  'two_identicle_SCG_RLF': 1155,\n",
       "  'two_identicle_RLF_SN_setup': 4303,\n",
       "  'pci_identicle_HO': 11973,\n",
       "  'pci_identicle_LTE_HO': 767,\n",
       "  'pci_identicle_MN_HO': 11070,\n",
       "  'pci_identicle_MN_HO_to_eNB': 136}}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dict_all = {}\n",
    "for k in keys:\n",
    "    analysis_dict_all[k] = {case: 0 for case in cases}\n",
    "\n",
    "for analysis_dict in analysis_dicts:\n",
    "    for k in keys:        \n",
    "        for i, case in enumerate(cases):\n",
    "            analysis_dict_all[k][case] += analysis_dict[k][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dl_loss': {'all': 63886,\n",
       "  'one_RLF': 35365,\n",
       "  'two_RLF': 22291,\n",
       "  'two_identicle_HO': 15569},\n",
       " 'dl_excl': {'all': 44934,\n",
       "  'one_RLF': 3937,\n",
       "  'two_RLF': 10727,\n",
       "  'two_identicle_HO': 5785},\n",
       " 'ul_loss': {'all': 3710,\n",
       "  'one_RLF': 1088,\n",
       "  'two_RLF': 221,\n",
       "  'two_identicle_HO': 209},\n",
       " 'ul_excl': {'all': 1031406,\n",
       "  'one_RLF': 21637,\n",
       "  'two_RLF': 49872,\n",
       "  'two_identicle_HO': 36238}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#06/data/diag_log_sm01_2023-06-12_17-16-04_rrc.csv'\n",
    "# L = parse_mi_ho(file)\n",
    "# L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm00/#06/data/diag_log_sm00_2023-06-12_17-16-04_rrc.csv\n",
    "# /home/wmnlab/D/database/2023-06-12/Bandlock_8_Schemes_Phone/sm01/#06/data/diag_log_sm01_2023-06-12_17-16-04_rrc.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73225"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35365+22291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
